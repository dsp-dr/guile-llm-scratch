[
  {
    "name": "fundamentals",
    "chapters": [
      1,
      2
    ],
    "pages": [
      0,
      50
    ],
    "max_size_mb": 2,
    "description": "LLM fundamentals and text processing",
    "output": {
      "filename": "fundamentals.pdf",
      "path": "book_chapters/fundamentals.pdf",
      "size_mb": 9.73,
      "page_count": 50
    }
  },
  {
    "name": "attention_architecture",
    "chapters": [
      3,
      4
    ],
    "pages": [
      50,
      150
    ],
    "max_size_mb": 3,
    "description": "Attention mechanisms and GPT architecture",
    "output": {
      "filename": "attention_architecture.pdf",
      "path": "book_chapters/attention_architecture.pdf",
      "size_mb": 4.48,
      "page_count": 100
    }
  },
  {
    "name": "training",
    "chapters": [
      5
    ],
    "pages": [
      150,
      220
    ],
    "max_size_mb": 2.5,
    "description": "Pretraining on unlabeled data",
    "output": {
      "filename": "training.pdf",
      "path": "book_chapters/training.pdf",
      "size_mb": 4.47,
      "page_count": 70
    }
  },
  {
    "name": "fine_tuning",
    "chapters": [
      6,
      7
    ],
    "pages": [
      220,
      370
    ],
    "max_size_mb": 3.5,
    "description": "Fine-tuning and instruction following",
    "output": {
      "filename": "fine_tuning.pdf",
      "path": "book_chapters/fine_tuning.pdf",
      "size_mb": 5.62,
      "page_count": 150
    }
  }
]